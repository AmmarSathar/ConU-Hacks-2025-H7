{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "\n",
    "# Load environmental data\n",
    "env_data = pd.read_csv('../Data/historical_environmental_data.csv', parse_dates=['timestamp'])\n",
    "# Load wildfire data\n",
    "fire_data = pd.read_csv('../Data/historical_wildfiredata.csv', parse_dates=['timestamp', 'fire_start_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "time_window_hours = 24 * 7  # 1 week\n",
    "max_distance_km = 50  # 50 km radius\n",
    "\n",
    "# Prepare to collect samples\n",
    "samples = []\n",
    "\n",
    "for idx, fire in fire_data.iterrows():\n",
    "    fire_time = fire['fire_start_time']\n",
    "    fire_loc = (fire['latitude'], fire['longitude'])\n",
    "    \n",
    "    # Filter environmental data within time window\n",
    "    mask = (env_data['timestamp'] >= fire_time - pd.Timedelta(hours=time_window_hours)) & \\\n",
    "           (env_data['timestamp'] < fire_time)\n",
    "    relevant_env = env_data[mask].copy()\n",
    "    \n",
    "    # Calculate distance to fire\n",
    "    relevant_env['distance'] = relevant_env.apply(\n",
    "        lambda row: haversine((row['latitude'], row['longitude']), fire_loc), axis=1\n",
    "    )\n",
    "    \n",
    "    # Filter by distance\n",
    "    nearby_env = relevant_env[relevant_env['distance'] <= max_distance_km]\n",
    "    \n",
    "    if not nearby_env.empty:\n",
    "        # Aggregate features (e.g., mean values)\n",
    "        aggregated = nearby_env.groupby('timestamp').agg({\n",
    "            'temperature': 'mean',\n",
    "            'humidity': 'mean',\n",
    "            'wind_speed': 'mean',\n",
    "            'precipitation': 'mean',\n",
    "            'vegetation_index': 'mean',\n",
    "            'human_activity_index': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Assign fire severity as target\n",
    "        aggregated['severity'] = fire['severity']\n",
    "        samples.append(aggregated)\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "if samples:\n",
    "    fire_features = pd.concat(samples)\n",
    "else:\n",
    "    raise ValueError(\"No overlapping environmental data found for fires.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate negative samples (no fires)\n",
    "non_fire_samples = env_data.sample(n=len(fire_data) * 10)  # Adjust based on your data\n",
    "non_fire_samples['severity'] = 'none'  # Indicate no fire\n",
    "\n",
    "# Combine positive and negative samples\n",
    "all_data = pd.concat([fire_features, non_fire_samples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode severity\n",
    "le = LabelEncoder()\n",
    "all_data['severity_encoded'] = le.fit_transform(all_data['severity'])\n",
    "\n",
    "# Features and target\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'precipitation', 'vegetation_index', 'human_activity_index']\n",
    "X = all_data[features]\n",
    "y = all_data['severity_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.16      0.05      0.07       171\n",
      "         low       0.35      0.56      0.43       362\n",
      "      medium       0.28      0.20      0.23       239\n",
      "        none       0.28      0.25      0.27       266\n",
      "\n",
      "    accuracy                           0.32      1038\n",
      "   macro avg       0.27      0.27      0.25      1038\n",
      "weighted avg       0.29      0.32      0.29      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "new_data = pd.DataFrame([{\n",
    "    'temperature': 30.0,\n",
    "    'humidity': 40,\n",
    "    'wind_speed': 20,\n",
    "    'precipitation': 0.5,\n",
    "    'vegetation_index': 50,\n",
    "    'human_activity_index': 30\n",
    "}])\n",
    "\n",
    "prediction = model.predict(new_data)\n",
    "print('Predicted severity:', le.inverse_transform(prediction)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real test for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp  temperature  humidity  wind_speed  precipitation  \\\n",
      "21   2025-01-01 21:00:00         37.1        46          38            4.1   \n",
      "45   2025-01-02 21:00:00         36.0        78          40            1.4   \n",
      "71   2025-01-03 23:00:00         20.0        65          29            5.0   \n",
      "106  2025-01-05 10:00:00         19.9        30          39            0.1   \n",
      "146  2025-01-07 02:00:00         36.8        69           0            3.0   \n",
      "...                  ...          ...       ...         ...            ...   \n",
      "8658 2025-12-27 18:00:00         37.4        77           9            2.6   \n",
      "8670 2025-12-28 06:00:00         18.0        28          19            1.8   \n",
      "8703 2025-12-29 15:00:00         37.1        85           8            2.2   \n",
      "8749 2025-12-31 13:00:00         25.1        79          32            2.9   \n",
      "8752 2025-12-31 16:00:00         27.3        87          38            1.4   \n",
      "\n",
      "      vegetation_index  human_activity_index  latitude  longitude fire_risk  \n",
      "21                  47                    65   45.8858   -73.8209      high  \n",
      "45                  30                    49   45.6260   -73.3525      high  \n",
      "71                  49                    34   45.6783   -72.2760      high  \n",
      "106                 73                    30   45.1976   -72.4879      high  \n",
      "146                 60                     5   44.0588   -72.7712      high  \n",
      "...                ...                   ...       ...        ...       ...  \n",
      "8658                76                    53   45.6863   -73.1721      high  \n",
      "8670                64                    49   45.0210   -72.0375      high  \n",
      "8703                65                    75   44.8493   -73.9574      high  \n",
      "8749                36                    48   44.0730   -73.9531      high  \n",
      "8752                34                    72   44.6364   -72.9507      high  \n",
      "\n",
      "[406 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load future environmental data (only once)\n",
    "future_env = pd.read_csv('../Data/future_environmental_data.csv', parse_dates=['timestamp'])\n",
    "\n",
    "# Select the same features used in training\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'precipitation', 'vegetation_index', 'human_activity_index']\n",
    "\n",
    "# Make predictions for all rows\n",
    "X_future = future_env[features]\n",
    "predictions = model.predict(X_future)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "future_env['fire_risk'] = le.inverse_transform(predictions)\n",
    "\n",
    "# Show results\n",
    "print(future_env[future_env['fire_risk'] == 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Model Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, '../../MlService/Models/wildfire_model.pkl')\n",
    "joblib.dump(le, '../../MlService/Models/label_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
