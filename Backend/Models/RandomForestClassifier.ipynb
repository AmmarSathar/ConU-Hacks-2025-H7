{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "\n",
    "# Load environmental data\n",
    "env_data = pd.read_csv('../Data/historical_environmental_data.csv', parse_dates=['timestamp'])\n",
    "# Load wildfire data\n",
    "fire_data = pd.read_csv('../Data/historical_wildfiredata.csv', parse_dates=['timestamp', 'fire_start_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "time_window_hours = 24 * 7  # 1 week\n",
    "max_distance_km = 50  # 50 km radius\n",
    "\n",
    "# Prepare to collect samples\n",
    "samples = []\n",
    "\n",
    "for idx, fire in fire_data.iterrows():\n",
    "    fire_time = fire['fire_start_time']\n",
    "    fire_loc = (fire['latitude'], fire['longitude'])\n",
    "    \n",
    "    # Filter environmental data within time window\n",
    "    mask = (env_data['timestamp'] >= fire_time - pd.Timedelta(hours=time_window_hours)) & \\\n",
    "           (env_data['timestamp'] < fire_time)\n",
    "    relevant_env = env_data[mask].copy()\n",
    "    \n",
    "    # Calculate distance to fire\n",
    "    relevant_env['distance'] = relevant_env.apply(\n",
    "        lambda row: haversine((row['latitude'], row['longitude']), fire_loc), axis=1\n",
    "    )\n",
    "    \n",
    "    # Filter by distance\n",
    "    nearby_env = relevant_env[relevant_env['distance'] <= max_distance_km]\n",
    "    \n",
    "    if not nearby_env.empty:\n",
    "        # Aggregate features (e.g., mean values)\n",
    "        aggregated = nearby_env.groupby('timestamp').agg({\n",
    "            'temperature': 'mean',\n",
    "            'humidity': 'mean',\n",
    "            'wind_speed': 'mean',\n",
    "            'precipitation': 'mean',\n",
    "            'vegetation_index': 'mean',\n",
    "            'human_activity_index': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Assign fire severity as target\n",
    "        aggregated['severity'] = fire['severity']\n",
    "        samples.append(aggregated)\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "if samples:\n",
    "    fire_features = pd.concat(samples)\n",
    "else:\n",
    "    raise ValueError(\"No overlapping environmental data found for fires.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate negative samples (no fires)\n",
    "non_fire_samples = env_data.sample(n=len(fire_data) * 10)  # Adjust based on your data\n",
    "non_fire_samples['severity'] = 'none'  # Indicate no fire\n",
    "\n",
    "# Combine positive and negative samples\n",
    "all_data = pd.concat([fire_features, non_fire_samples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode severity\n",
    "le = LabelEncoder()\n",
    "all_data['severity_encoded'] = le.fit_transform(all_data['severity'])\n",
    "\n",
    "# Features and target\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'precipitation', 'vegetation_index', 'human_activity_index']\n",
    "X = all_data[features]\n",
    "y = all_data['severity_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "new_data = pd.DataFrame([{\n",
    "    'temperature': 30.0,\n",
    "    'humidity': 40,\n",
    "    'wind_speed': 20,\n",
    "    'precipitation': 0.5,\n",
    "    'vegetation_index': 50,\n",
    "    'human_activity_index': 30\n",
    "}])\n",
    "\n",
    "prediction = model.predict(new_data)\n",
    "print('Predicted severity:', le.inverse_transform(prediction)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real test for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load future environmental data (only once)\n",
    "future_env = pd.read_csv('../Data/future_environmental_data.csv', parse_dates=['timestamp'])\n",
    "\n",
    "# Select the same features used in training\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'precipitation', 'vegetation_index', 'human_activity_index']\n",
    "\n",
    "# Make predictions for all rows\n",
    "X_future = future_env[features]\n",
    "predictions = model.predict(X_future)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "future_env['fire_risk'] = le.inverse_transform(predictions)\n",
    "\n",
    "# Show results\n",
    "print(future_env[future_env['fire_risk'] == 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Model Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'wildfire_model.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
